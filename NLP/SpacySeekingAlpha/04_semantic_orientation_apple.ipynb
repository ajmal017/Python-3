{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client.python_import\n",
    "collection = db.earnings_transcript_NAS100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = pd.DataFrame(list(collection.find({'tradingSymbol':'AAPL'})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countvectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "def tokenize(sent):\n",
    "    return [tok.lemma_ for tok in sent if not tok.pos_ == 'PUNCT' and tok.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = nlp('Hello you 2-faced god. Let me show you some a+ hotels.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sent in test.sents:\n",
    "#    print([tok for tok in sent if not tok.pos_ == 'PUNCT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model = CountVectorizer(ngram_range=(1,1), tokenizer=tokenize, lowercase=False, min_df=3, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = transcripts['rawText'].apply(lambda row: list(nlp(row).sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_flattened = corpus.apply(pd.Series).stack().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_transcripts = count_model.fit_transform(corpus_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19932x3132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 277186 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'nasdaq',\n",
       " 'aapl',\n",
       " 'earning',\n",
       " 'call',\n",
       " 'january',\n",
       " 'pm',\n",
       " 'et',\n",
       " 'executives',\n",
       " 'nancy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(count_model.vocabulary_.keys())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-occurrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed = counted_transcripts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence = transposed * counted_transcripts\n",
    "co_occurrence.setdiag(0)\n",
    "co_occurrence = co_occurrence.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing term probabilites\n",
    "Document Frequency (DF) of a term as the number of documents where the term occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19932"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_count = counted_transcripts.shape[0]\n",
    "document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = np.count_nonzero(counted_transcripts.todense(), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3132)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_term = document_frequency/document_count\n",
    "prob_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3132, 3132)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_term_coocc = co_occurrence/document_count\n",
    "prob_term_coocc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing PMI and the semantic orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = pd.read_csv('positive-words.txt')\n",
    "negative_words = pd.read_csv('negative-words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = count_model.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "PMI = np.log(prob_term_coocc/(prob_term.T*prob_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI[PMI == -np.inf] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMI = np.array(PMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3132, 3132)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PMI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_assoc(words, vocabulary_index):\n",
    "    assoc = 0\n",
    "    for pos_word in words:\n",
    "        if pos_word in vocabulary:\n",
    "            assoc += PMI[vocabulary_index][vocabulary[pos_word]]\n",
    "    return assoc\n",
    "\n",
    "semantic_orientation = {}\n",
    "            \n",
    "for vocabulary_item, vocabulary_index in vocabulary.items():\n",
    "    positive_assoc = calc_assoc(positive_words.Word, vocabulary_index)\n",
    "    negative_assoc = calc_assoc(negative_words.Word, vocabulary_index)\n",
    "    semantic_orientation[vocabulary_item] = positive_assoc - negative_assoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_sorted = sorted(semantic_orientation, \n",
    "                         key=semantic_orientation.get, \n",
    "                         reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pos = semantic_sorted[:20]\n",
    "top_neg = semantic_sorted[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer',\n",
       " 'and',\n",
       " 'app',\n",
       " 'new',\n",
       " 'experience',\n",
       " 'design',\n",
       " 'performance',\n",
       " 'feature',\n",
       " 'ios',\n",
       " 'work',\n",
       " 'developer',\n",
       " 'team',\n",
       " 'apps',\n",
       " 'product',\n",
       " 'continue',\n",
       " 'most',\n",
       " 'very',\n",
       " 'to',\n",
       " 'these',\n",
       " 'more']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh',\n",
       " 'signing',\n",
       " 'um',\n",
       " 'expect',\n",
       " 'thank',\n",
       " 'require',\n",
       " 'piece',\n",
       " 'currency',\n",
       " 'apologize',\n",
       " 'expense',\n",
       " 'cause',\n",
       " 'budget',\n",
       " 'subsidy',\n",
       " 'nuclear',\n",
       " 'disruption',\n",
       " 'subsequent',\n",
       " 'alleviate',\n",
       " 'any',\n",
       " 'please',\n",
       " 'question']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
